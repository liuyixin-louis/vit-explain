{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yila22/anaconda3/envs/geomloss/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Using cache found in /home/yila22/.cache/torch/hub/facebookresearch_deit_main\n"
     ]
    }
   ],
   "source": [
    "from vit_rollout import VITAttentionRollout\n",
    "import torch\n",
    "model = torch.hub.load('facebookresearch/deit:main', \n",
    "'deit_tiny_patch16_224', pretrained=True)\n",
    "rollout = VITAttentionRollout(model, discard_ratio=0.9, head_fusion='max')\n",
    "# mask = grad_rollout(input_tensor, category_index=243)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import timm\n",
    "# from pprint import pprint\n",
    "# model_names = timm.list_models(pretrained=True)\n",
    "# pprint(model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import timm\n",
    "\n",
    "# m = timm.create_model('vit_base_patch16_224', pretrained=True)\n",
    "# m.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m.forward_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load pickle file\n",
    "# import pickle\n",
    "# with open('/home/yila22/prj/vision-transformers-cifar10/checkpoint/vit_timm-4-ckpt.t7', 'rb') as f:\n",
    "#     data = pickle.load(f)\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read image and convert to tensor\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "img = Image.open(\"both.png\")\n",
    "# convert_tensor = transforms.ToTensor()\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    "\n",
    "# img = transform(img).unsqueeze(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.axis('off')\n",
    "# plt.imshow(img[0].permute(1,2,0), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = rollout(\n",
    "    img\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.set(font_scale=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = torch.tensor(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the image\n",
    "import matplotlib.pyplot as plt\n",
    "# plt.imshow(img)\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def show_cam_on_image(img, mask):\n",
    "    heatmap = cv2.applyColorMap(np.uint8(255 * mask), cv2.COLORMAP_JET)\n",
    "    heatmap = np.float32(heatmap) / 255\n",
    "    cam = 0.7 * heatmap + 0.3 * np.float32(img)\n",
    "    cam = cam / np.max(cam)\n",
    "    return cam\n",
    "\n",
    "def show_mask_on_image(img, mask, mask_size, patch_size, image_size):\n",
    "    mask = mask.reshape(1, 1, mask_size,mask_size)\n",
    "    mask =  torch.nn.functional.interpolate(mask, scale_factor=patch_size, mode='bilinear')\n",
    "    mask = mask.reshape(image_size, image_size).cuda().data.cpu().numpy()\n",
    "    mask = (mask - mask.min()) / (mask.max() - mask.min())\n",
    "    # # mask.shape\n",
    "    # # mix the mask and the image\n",
    "\n",
    "    vis = show_cam_on_image(img[0].permute(1,2,0), mask)\n",
    "    # # vis =  np.uint8(255 * vis)\n",
    "    vis = cv2.cvtColor(np.array(vis), cv2.COLOR_RGB2BGR)\n",
    "    # plt.axis('off')\n",
    "    # plot two subplots\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(20, 10))\n",
    "    # plt.axis('off')\n",
    "    ax[0].imshow(img[0].permute(1,2,0))\n",
    "    # plt.axis('off')\n",
    "    ax[1].imshow(vis)\n",
    "    # plt.imshow(img[0].permute(1,2,0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.axis('off')\n",
    "# plt.imshow(mask, cmap='jet', alpha=0.5)\n",
    "# plt.savefig('mask.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.axis('off')\n",
    "# plt.imshow(img[0].permute(1,2,0))\n",
    "# plt.savefig('img.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    " \n",
    "# img_path = 'img.png'\n",
    "# mask_path = 'mask.png'\n",
    " \n",
    "# img = plt.imread(img_path)\n",
    "# mask = plt.imread(mask_path)\n",
    "\n",
    "# frame = plt.gca()\n",
    "# # y 轴不可见\n",
    "# frame.axes.get_yaxis().set_visible(False)\n",
    "# # x 轴不可见\n",
    "# frame.axes.get_xaxis().set_visible(False)\n",
    "\n",
    "# plt.axis('off')\n",
    "# #叠加显示img, mask\n",
    "# plt.imshow(img, )\n",
    "\n",
    "# plt.imshow(mask, alpha=0.7, cmap='jet')  #alpha设置透明度, cmap可以选择颜色\n",
    "# plt.xticks([])\n",
    "# plt.savefig('att.png', bbox_inches='tight', pad_inches=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "\n",
    "# def norm_image(image):\n",
    "#     \"\"\"\n",
    "#     Normalization image\n",
    "#     :param image: [H,W,C]\n",
    "#     :return:\n",
    "#     \"\"\"\n",
    "#     image = image.copy()\n",
    "#     image -= np.max(np.min(image), 0)\n",
    "#     image /= np.max(image)\n",
    "#     image *= 255.\n",
    "#     return np.uint8(image)\n",
    "\n",
    "# def visualize_heatmap(image, mask):\n",
    "#     '''\n",
    "#     Save the heatmap of ones\n",
    "#     '''\n",
    "#     masks = norm_image(mask).astype(np.uint8)\n",
    "#     # mask->heatmap\n",
    "#     heatmap = cv2.applyColorMap(masks, cv2.COLORMAP_JET)\n",
    "#     heatmap = np.float32(heatmap)\n",
    "\n",
    "#     heatmap = cv2.resize(heatmap, (image.shape[1], image.shape[0]))    # same shape\n",
    "\n",
    "#     # merge heatmap to original image\n",
    "#     cam = 0.4*heatmap + 0.6*np.float32(image)\n",
    "#     return cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_reshaped = img.reshape(224, 224,3).cpu().numpy()\n",
    "# # img_reshaped = norm_image(img_reshaped)\n",
    "# cam = visualize_heatmap(img_reshaped, mask)\n",
    "# plt.imshow(cam)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting foolbox\n",
      "  Downloading foolbox-3.3.3-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /home/yila22/anaconda3/envs/geomloss/lib/python3.8/site-packages (from foolbox) (65.4.0)\n",
      "Requirement already satisfied: requests>=2.24.0 in /home/yila22/anaconda3/envs/geomloss/lib/python3.8/site-packages (from foolbox) (2.28.1)\n",
      "Collecting eagerpy>=0.30.0\n",
      "  Downloading eagerpy-0.30.0-py3-none-any.whl (31 kB)\n",
      "Collecting scipy\n",
      "  Downloading scipy-1.9.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.8/33.8 MB\u001b[0m \u001b[31m81.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/yila22/anaconda3/envs/geomloss/lib/python3.8/site-packages (from foolbox) (1.23.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.1 in /home/yila22/anaconda3/envs/geomloss/lib/python3.8/site-packages (from foolbox) (4.3.0)\n",
      "Requirement already satisfied: GitPython>=3.0.7 in /home/yila22/anaconda3/envs/geomloss/lib/python3.8/site-packages (from foolbox) (3.1.29)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/yila22/anaconda3/envs/geomloss/lib/python3.8/site-packages (from GitPython>=3.0.7->foolbox) (4.0.9)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/yila22/anaconda3/envs/geomloss/lib/python3.8/site-packages (from requests>=2.24.0->foolbox) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/yila22/anaconda3/envs/geomloss/lib/python3.8/site-packages (from requests>=2.24.0->foolbox) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/yila22/anaconda3/envs/geomloss/lib/python3.8/site-packages (from requests>=2.24.0->foolbox) (1.26.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/yila22/anaconda3/envs/geomloss/lib/python3.8/site-packages (from requests>=2.24.0->foolbox) (3.4)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/yila22/anaconda3/envs/geomloss/lib/python3.8/site-packages (from gitdb<5,>=4.0.1->GitPython>=3.0.7->foolbox) (5.0.0)\n",
      "Installing collected packages: scipy, eagerpy, foolbox\n",
      "Successfully installed eagerpy-0.30.0 foolbox-3.3.3 scipy-1.9.3\n"
     ]
    }
   ],
   "source": [
    "!pip install foolbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = torch.LongTensor([0]*1000)\n",
    "labels[282] = 1\n",
    "labels = labels.reshape(1, 1000)\n",
    "images = img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1000])"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1000])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(images)\n",
    "    print(logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yila22/anaconda3/envs/geomloss/lib/python3.8/site-packages/foolbox/models/pytorch.py:36: UserWarning: The PyTorch model is in training mode and therefore might not be deterministic. Call the eval() method to set it in evaluation mode if this is not intended.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "labels must be 1D and must match the length of logits",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [268], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m attack \u001b[39m=\u001b[39m fb\u001b[39m.\u001b[39mattacks\u001b[39m.\u001b[39mLinfPGD()\n\u001b[1;32m      5\u001b[0m epsilons \u001b[39m=\u001b[39m [\u001b[39m0\u001b[39m, \u001b[39m0.1\u001b[39m]\n\u001b[0;32m----> 6\u001b[0m _, advs, success \u001b[39m=\u001b[39m attack(fmodel, images, labels, epsilons\u001b[39m=\u001b[39;49mepsilons)\n",
      "File \u001b[0;32m~/anaconda3/envs/geomloss/lib/python3.8/site-packages/foolbox/attacks/base.py:283\u001b[0m, in \u001b[0;36mFixedEpsilonAttack.__call__\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    281\u001b[0m success \u001b[39m=\u001b[39m []\n\u001b[1;32m    282\u001b[0m \u001b[39mfor\u001b[39;00m epsilon \u001b[39min\u001b[39;00m real_epsilons:\n\u001b[0;32m--> 283\u001b[0m     xp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun(model, x, criterion, epsilon\u001b[39m=\u001b[39;49mepsilon, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    285\u001b[0m     \u001b[39m# clip to epsilon because we don't really know what the attack returns;\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# alternatively, we could check if the perturbation is at most epsilon,\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39m# but then we would need to handle numerical violations;\u001b[39;00m\n\u001b[1;32m    288\u001b[0m     xpc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistance\u001b[39m.\u001b[39mclip_perturbation(x, xp, epsilon)\n",
      "File \u001b[0;32m~/anaconda3/envs/geomloss/lib/python3.8/site-packages/foolbox/attacks/gradient_descent_base.py:155\u001b[0m, in \u001b[0;36mBaseGradientDescent.run\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    152\u001b[0m     x \u001b[39m=\u001b[39m x0\n\u001b[1;32m    154\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps):\n\u001b[0;32m--> 155\u001b[0m     _, gradients \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvalue_and_grad(loss_fn, x)\n\u001b[1;32m    156\u001b[0m     gradients \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnormalize(gradients, x\u001b[39m=\u001b[39mx, bounds\u001b[39m=\u001b[39mmodel\u001b[39m.\u001b[39mbounds)\n\u001b[1;32m    157\u001b[0m     x \u001b[39m=\u001b[39m x \u001b[39m+\u001b[39m gradient_step_sign \u001b[39m*\u001b[39m optimizer(gradients)\n",
      "File \u001b[0;32m~/anaconda3/envs/geomloss/lib/python3.8/site-packages/foolbox/attacks/gradient_descent_base.py:111\u001b[0m, in \u001b[0;36mBaseGradientDescent.value_and_grad\u001b[0;34m(self, loss_fn, x)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvalue_and_grad\u001b[39m(\n\u001b[1;32m    106\u001b[0m     \u001b[39m# can be overridden by users\u001b[39;00m\n\u001b[1;32m    107\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    108\u001b[0m     loss_fn: Callable[[ep\u001b[39m.\u001b[39mTensor], ep\u001b[39m.\u001b[39mTensor],\n\u001b[1;32m    109\u001b[0m     x: ep\u001b[39m.\u001b[39mTensor,\n\u001b[1;32m    110\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[ep\u001b[39m.\u001b[39mTensor, ep\u001b[39m.\u001b[39mTensor]:\n\u001b[0;32m--> 111\u001b[0m     \u001b[39mreturn\u001b[39;00m ep\u001b[39m.\u001b[39;49mvalue_and_grad(loss_fn, x)\n",
      "File \u001b[0;32m~/anaconda3/envs/geomloss/lib/python3.8/site-packages/eagerpy/framework.py:360\u001b[0m, in \u001b[0;36mvalue_and_grad\u001b[0;34m(f, t, *args, **kwargs)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvalue_and_grad\u001b[39m(\n\u001b[1;32m    358\u001b[0m     f: Callable[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m, TensorType], t: TensorType, \u001b[39m*\u001b[39margs: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any\n\u001b[1;32m    359\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[TensorType, TensorType]:\n\u001b[0;32m--> 360\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39;49mvalue_and_grad(f, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/geomloss/lib/python3.8/site-packages/eagerpy/tensor/tensor.py:553\u001b[0m, in \u001b[0;36mTensor.value_and_grad\u001b[0;34m(self, f, *args, **kwargs)\u001b[0m\n\u001b[1;32m    549\u001b[0m \u001b[39m@final\u001b[39m\n\u001b[1;32m    550\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvalue_and_grad\u001b[39m(\n\u001b[1;32m    551\u001b[0m     \u001b[39mself\u001b[39m: TensorType, f: Callable[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m, TensorType], \u001b[39m*\u001b[39margs: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any\n\u001b[1;32m    552\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[TensorType, TensorType]:\n\u001b[0;32m--> 553\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_value_and_grad_fn(f, has_aux\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/geomloss/lib/python3.8/site-packages/eagerpy/tensor/pytorch.py:505\u001b[0m, in \u001b[0;36mPyTorchTensor._value_and_grad_fn.<locals>.value_and_grad\u001b[0;34m(x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    503\u001b[0m     loss, aux \u001b[39m=\u001b[39m f(x, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    504\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 505\u001b[0m     loss \u001b[39m=\u001b[39m f(x, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    506\u001b[0m loss \u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mraw\n\u001b[1;32m    507\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/anaconda3/envs/geomloss/lib/python3.8/site-packages/foolbox/attacks/gradient_descent_base.py:97\u001b[0m, in \u001b[0;36mBaseGradientDescent.get_loss_fn.<locals>.loss_fn\u001b[0;34m(inputs)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mloss_fn\u001b[39m(inputs: ep\u001b[39m.\u001b[39mTensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ep\u001b[39m.\u001b[39mTensor:\n\u001b[1;32m     96\u001b[0m     logits \u001b[39m=\u001b[39m model(inputs)\n\u001b[0;32m---> 97\u001b[0m     \u001b[39mreturn\u001b[39;00m ep\u001b[39m.\u001b[39;49mcrossentropy(logits, labels)\u001b[39m.\u001b[39msum()\n",
      "File \u001b[0;32m~/anaconda3/envs/geomloss/lib/python3.8/site-packages/eagerpy/framework.py:325\u001b[0m, in \u001b[0;36mcrossentropy\u001b[0;34m(logits, labels)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcrossentropy\u001b[39m(logits: TensorType, labels: TensorType) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m TensorType:\n\u001b[0;32m--> 325\u001b[0m     \u001b[39mreturn\u001b[39;00m logits\u001b[39m.\u001b[39;49mcrossentropy(labels)\n",
      "File \u001b[0;32m~/anaconda3/envs/geomloss/lib/python3.8/site-packages/eagerpy/tensor/pytorch.py:468\u001b[0m, in \u001b[0;36mPyTorchTensor.crossentropy\u001b[0;34m(self, labels)\u001b[0m\n\u001b[1;32m    466\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mcrossentropy only supported for 2D logits tensors\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    467\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshape[:\u001b[39m1\u001b[39m] \u001b[39m!=\u001b[39m labels\u001b[39m.\u001b[39mshape:\n\u001b[0;32m--> 468\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mlabels must be 1D and must match the length of logits\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    469\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)(\n\u001b[1;32m    470\u001b[0m     torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39mcross_entropy(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw, labels\u001b[39m.\u001b[39mraw, reduction\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mnone\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    471\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: labels must be 1D and must match the length of logits"
     ]
    }
   ],
   "source": [
    "import foolbox as fb\n",
    "images = images.cuda()\n",
    "fmodel = fb.PyTorchModel(model, bounds=(images.min(), images.max()))\n",
    "attack = fb.attacks.LinfPGD()\n",
    "epsilons = [0, 0.1]\n",
    "_, advs, success = attack(fmodel, images, labels, epsilons=epsilons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected floating point type for target with class probabilities, got Long",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [273], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39m# If, images are normalized:\u001b[39;00m\n\u001b[1;32m      4\u001b[0m atk\u001b[39m.\u001b[39mset_normalization_used(mean\u001b[39m=\u001b[39m[\u001b[39m0.5\u001b[39m, \u001b[39m0.5\u001b[39m, \u001b[39m0.5\u001b[39m], std\u001b[39m=\u001b[39m[\u001b[39m0.5\u001b[39m, \u001b[39m0.5\u001b[39m, \u001b[39m0.5\u001b[39m])\n\u001b[0;32m----> 5\u001b[0m adv_images \u001b[39m=\u001b[39m atk(images, labels)\n",
      "File \u001b[0;32m~/anaconda3/envs/geomloss/lib/python3.8/site-packages/torchattacks/attack.py:423\u001b[0m, in \u001b[0;36mAttack.__call__\u001b[0;34m(self, inputs, labels, *args, **kwargs)\u001b[0m\n\u001b[1;32m    420\u001b[0m inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minverse_normalize(inputs)\n\u001b[1;32m    421\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_normalization_applied(\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m--> 423\u001b[0m adv_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(inputs, labels, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    424\u001b[0m adv_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_type(adv_inputs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_type)\n\u001b[1;32m    426\u001b[0m adv_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnormalize(adv_inputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/geomloss/lib/python3.8/site-packages/torchattacks/attacks/pgd.py:67\u001b[0m, in \u001b[0;36mPGD.forward\u001b[0;34m(self, images, labels)\u001b[0m\n\u001b[1;32m     65\u001b[0m     cost \u001b[39m=\u001b[39m \u001b[39m-\u001b[39mloss(outputs, target_labels)\n\u001b[1;32m     66\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 67\u001b[0m     cost \u001b[39m=\u001b[39m loss(outputs, labels)\n\u001b[1;32m     69\u001b[0m \u001b[39m# Update adversarial images\u001b[39;00m\n\u001b[1;32m     70\u001b[0m grad \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mgrad(cost, adv_images,\n\u001b[1;32m     71\u001b[0m                            retain_graph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, create_graph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/geomloss/lib/python3.8/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/geomloss/lib/python3.8/site-packages/torch/nn/modules/loss.py:1174\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1173\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor, target: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m-> 1174\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mcross_entropy(\u001b[39minput\u001b[39;49m, target, weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight,\n\u001b[1;32m   1175\u001b[0m                            ignore_index\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mignore_index, reduction\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduction,\n\u001b[1;32m   1176\u001b[0m                            label_smoothing\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlabel_smoothing)\n",
      "File \u001b[0;32m~/anaconda3/envs/geomloss/lib/python3.8/site-packages/torch/nn/functional.py:3026\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3024\u001b[0m \u001b[39mif\u001b[39;00m size_average \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m reduce \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   3025\u001b[0m     reduction \u001b[39m=\u001b[39m _Reduction\u001b[39m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3026\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49mcross_entropy_loss(\u001b[39minput\u001b[39;49m, target, weight, _Reduction\u001b[39m.\u001b[39;49mget_enum(reduction), ignore_index, label_smoothing)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected floating point type for target with class probabilities, got Long"
     ]
    }
   ],
   "source": [
    "\n",
    "import torchattacks\n",
    "torch.backends.cudnn.deterministic = True\n",
    "atk = torchattacks.PGD(model, eps=8/255, alpha=2/255, steps=4)\n",
    "# If, images are normalized:\n",
    "atk.set_normalization_used(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "adv_images = atk(images, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sampling loop time step: 100%|██████████| 1000/1000 [28:37<00:00,  1.72s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 128, 128])"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from denoising_diffusion_pytorch import Unet, GaussianDiffusion\n",
    "\n",
    "model = Unet(\n",
    "    dim = 64,\n",
    "    dim_mults = (1, 2, 4, 8)\n",
    ")\n",
    "\n",
    "diffusion = GaussianDiffusion(\n",
    "    model,\n",
    "    image_size = 128,\n",
    "    timesteps = 1000,   # number of steps\n",
    "    loss_type = 'l1'    # L1 or L2\n",
    ")\n",
    "\n",
    "training_images = torch.randn(8, 3, 128, 128) # images are normalized from 0 to 1\n",
    "loss = diffusion(training_images)\n",
    "loss.backward()\n",
    "# after a lot of training\n",
    "\n",
    "sampled_images = diffusion.sample(batch_size = 4)\n",
    "sampled_images.shape # (4, 3, 128, 128)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smooth-vit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "afe178e8a180325ae5590b0a9f7d549c979d108f7c1523fed76d89f80b31158a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
